{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "\n",
    "question_system_prompt = \"You are provided with a technical question about AI and LLMs \\\n",
    "Provide the most accurate answer and explain in detail to a student of LLM engineering the answer \\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's break down the provided code snippet step by step, especially in the context of Python, which appears to be the language in use.\n",
       "\n",
       "python\n",
       "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
       "\n",
       "\n",
       "### Detailed Explanation:\n",
       "\n",
       "1. **Context of `yield`**:\n",
       "   - The `yield` keyword is part of Python's generator functionality. When you use `yield`, the function becomes a generator, allowing it to produce a series of values over time instead of computing them all at once and returning them.\n",
       "   - In this context, `yield from` is used to delegate part of the generator's operations to another generator or iterable. It effectively yields all values from the iterable without needing to loop through it explicitly.\n",
       "\n",
       "2. **Set comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension. This is a concise and readable way to create a set from the `books` collection.\n",
       "   - The expression iterates through a collection named `books`, which we can assume is a list (or some other iterable) of dictionaries (each dictionary representing a book).\n",
       "\n",
       "3. **What does `book.get(\"author\")` do?**:\n",
       "   - In each iteration, `book.get(\"author\")` retrieves the value associated with the key `\"author\"` from each dictionary (representing a book). If the author key does not exist in the dictionary, `get` will return `None` instead of raising a KeyError.\n",
       "   - The `if book.get(\"author\")` condition filters out any books that do not have an author defined. If the `get` method returns `None`, that book will not be included in the new set. This means only books with valid author names will be processed.\n",
       "\n",
       "4. **Result - Set of Authors**:\n",
       "   - The result of the set comprehension is a set of unique author names from the `books` collection. Since it’s a set, any duplicate author names will be automatically removed.\n",
       "\n",
       "5. **Final Output of `yield from`**:\n",
       "   - Using `yield from` here allows the generator to yield each unique author name from the set one by one. It effectively pulls values from the set and yields them to whatever is consuming this generator. \n",
       "\n",
       "### Summary Example:\n",
       "\n",
       "Suppose the `books` collection looks like this:\n",
       "\n",
       "python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\", \"author\": \"Author B\"},\n",
       "    {\"title\": \"Book 3\"},  # No author\n",
       "    {\"title\": \"Book 4\", \"author\": \"Author A\"},  # Duplicate author\n",
       "    {\"title\": \"Book 5\", \"author\": \"Author C\"}\n",
       "]\n",
       "\n",
       "\n",
       "When you run the line of code, the resulting set comprehension `{book.get(\"author\") for book in books if book.get(\"author\")}` would produce:\n",
       "\n",
       "python\n",
       "{\"Author A\", \"Author B\", \"Author C\"}\n",
       "\n",
       "\n",
       "When the generator yields from this set, it will yield `Author A`, then `Author B`, and finally `Author C`.\n",
       "\n",
       "### Conclusion:\n",
       "In summary, the code snippet creates a generator that yields each unique author from a list of books, ensuring that only those books that have specified authors are included, filtering out any that don't. The use of `yield from` makes this process efficient and keeps the code clean and readable."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "\n",
    "def stream_question_answer(question):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": question_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "stream_question_answer(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94af4f33-2baa-4d7c-9a45-ba9668ac0fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Breaking Down the Code**\n",
       "\n",
       "This line of code is written in Python and utilizes a feature called \"async generator\" or \"coroutine\" with yield from. Here's a breakdown of what it does:\n",
       "\n",
       "- `yield from`: This keyword allows us to delegate part of the execution of a coroutine to another asynchronous generator.\n",
       "- `{book.get(\"author\") for book in books if book.get(\"author\")}`: This is an asynchronous generator expression, which behaves similarly to a list comprehension. However, instead of evaluating an expression and returning it immediately, an asynchronous generator yields control to itself between each iteration.\n",
       "\n",
       "Let's break down the logic:\n",
       "\n",
       "1. `for book in books`: Iterates over some collection (e.g., a list or dictionary) called `books`. Each item in this collection is expected to be another iterable like a dictionary or something that doesn't matter for the comprehension.\n",
       "\n",
       "2. `if book.get(\"author\")`: Before considering each item, checks whether it has a key named `\"author\"`. If not, this item will be skipped.\n",
       "\n",
       "3. `yield from ...`: The items in this comprehension (which is basically filtering and iterating over `book`) when we use yield from the generator becomes to get one element on a loop calling  it inside where to call the code inside if the value passed into\n",
       "\n",
       "In terms of what it yields, consider what it does without yield from:\n",
       "\n",
       "`{item: book dictionary for book in books if book.get(\"author\")} => [{'author': author} for book in books if book.get('author')]` \n",
       "\n",
       "Now if we use `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`\n",
       "\n",
       "   - Yield items until no item is left.\n",
       "\n",
       "So what's that?\n",
       "\n",
       "yield from allows to turn those comprehension into an yield one. By using the key `.get()` which gets the key if its exists else will returns `None` this can lead us to a  code like:\n",
       "  \n",
       "\n",
       " \n",
       "    async function books():\n",
       "      const authors = await (yield from {book.get(\"author\") for book in books if book.get(\"author\")});\n",
       "\n",
       "      return authors;\n",
       "\n",
       "Here you would get all values for the `'author'` key and the function gets to run and wait for them before returning.\n",
       "\n",
       "javascript\n",
       "const books = async () => {\n",
       "  const authors = await ( yield from {book.get(\"author\") for book in books if book.get(\"author\")} );\n",
       "\n",
       "  return authors;\n",
       "}\n",
       "\n",
       "books();\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "\n",
    "def stream_question_answer_local(question):\n",
    "    ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL_LLAMA,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": question_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "          ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "\n",
    "stream_question_answer_local(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
